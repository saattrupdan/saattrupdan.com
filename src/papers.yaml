2024:

  - title: The Virtual Large Cardinal Hierarchy
    url: https://doi.org/10.48550/arXiv.2109.06079
    authors:
      - Stamatis Dimopoulos
      - Victoria Gitman
      - Dan Saattrup Nielsen
    venue: Fundamenta Mathematicae
    abstract: We continue the study of the virtual large cardinal hierarchy by analysing virtual versions of superstrong, Woodin, and Berkeley cardinals. Gitman and Schindler showed that virtualizations of strong and supercompact cardinals yield the same large cardinal notion. We provide various equivalent characterizations of virtually Woodin cardinals, including showing that On is virtually Woodin if and only if for every class A, there is a proper class of virtually A-extendible cardinals. We introduce the virtual Vopenka principle for finite languages and show that it is not equivalent to the virtual Vopenka principle (although the two principles are equiconsistent), but is equivalent to the assertion that On is virtually pre-Woodin, a weakening of virtually Woodin, which is equivalent to having for every class A, a weakly virtually A-extendible cardinal. We show that if there are no virtually Berkeley cardinals, then On is virtually Woodin if and only if On is virtually pre-Woodin (if and only if the virtual Vopenka principle for finite languages holds). In particular, if the virtual Vopenka principle holds and On is not Mahlo, then On is not virtually Woodin, and hence there is a virtually Berkeley cardinal.


2023:

  - title: Danish Foundation Models
    url: https://doi.org/10.48550/arXiv.2311.07264
    authors:
      - Kenneth Enevoldsen
      - Lasse Hansen
      - Dan Saattrup Nielsen
      - Rasmus A. F. Egebæk
      - Søren V. Holm
      - Martin C. Nielsen
      - Martin Bernstorff
      - Rasmus Larsen
      - Peter B. Jørgensen
      - Malte Højmark-Bertelsen
      - Peter B. Vahlstrup
      - Per Møldrup-Dalum
      - Kristoffer Nielbo
    venue: ArXiv preprint
    abstract: Large language models, sometimes referred to as foundation models, have transformed multiple fields of research. However, smaller languages risk falling behind due to high training costs and small incentives for large companies to train these models. To combat this, the Danish Foundation Models project seeks to provide and maintain open, well-documented, and high-quality foundation models for the Danish language. This is achieved through broad cooperation with public and private institutions, to ensure high data quality and applicability of the trained models. We present the motivation of the project, the current status, and future perspectives.

  - title: Model Agnostic Explainable Selective Regression via Uncertainty Estimation
    url: https://doi.org/10.48550/arXiv.2311.09145
    authors:
      - Andrea Pugnana
      - Carlos Mougan
      - Dan Saattrup Nielsen
    venue: ArXiv preprint
    abstract: With the wide adoption of machine learning techniques, requirements have evolved beyond sheer high performance, often requiring models to be trustworthy. A common approach to increase the trustworthiness of such systems is to allow them to refrain from predicting. Such a framework is known as selective prediction. While selective prediction for classification tasks has been widely analyzed, the problem of selective regression is understudied. This paper presents a novel approach to selective regression that utilizes model-agnostic non-parametric uncertainty estimation. Our proposed framework showcases superior performance compared to state-of-the-art selective regressors, as demonstrated through comprehensive benchmarking on 69 datasets. Finally, we use explainable AI techniques to gain an understanding of the drivers behind selective regression. We implement our selective regression method in the open-source Python package doubt and release the code used to reproduce our experiments.

  - title: ScandEval - A Benchmark for Scandinavian Natural Language Processing
    url: https://doi.org/10.48550/arXiv.2304.00906
    authors:
      - Dan Saattrup Nielsen
    venue: NoDaLiDa 2023
    abstract: This paper introduces a Scandinavian benchmarking platform, ScandEval, which can benchmark any pretrained model on four different tasks in the Scandinavian languages. The datasets used in two of the tasks, linguistic acceptability and question answering, are new. We develop and release a Python package and command-line interface, scandeval, which can benchmark any model that has been uploaded to the Hugging Face Hub, with reproducible results. Using this package, we benchmark more than 80 Scandinavian or multilingual models and present the results of these in an interactive online leaderboard, as well as provide an analysis of the results. The analysis shows that there is substantial cross-lingual transfer among the the Mainland Scandinavian languages (Danish, Swedish and Norwegian), with limited cross-lingual transfer between the group of Mainland Scandinavian languages and the group of Insular Scandinavian languages (Icelandic and Faroese). The benchmarking results also show that the investment in language technology in Norway and Sweden has led to language models that outperform massively multilingual models such as XLM-RoBERTa and mDeBERTaV3. We release the source code for both the package.

  - title: Addressing contingency in algorithmic (mis)information classification - Toward a responsible machine learning agenda
    url: https://doi.org/10.48550/arXiv.2210.09014
    authors:
      - Andrés Domínguez Hernández
      - Richard Owen
      - Dan Saattrup Nielsen
      - Ryan McConville
    venue: FAccT 2023 and Journal of Responsible Innovation
    abstract: Machine learning (ML) enabled classification models are becoming increasingly popular for tackling the sheer volume and speed of online misinformation and other content that could be identified as harmful. In building these models, data scientists need to take a stance on the legitimacy, authoritativeness and objectivity of the sources of ``truth" used for model training and testing. This has political, ethical and epistemic implications which are rarely addressed in technical papers. Despite (and due to) their reported high accuracy and performance, ML-driven moderation systems have the potential to shape online public debate and create downstream negative impacts such as undue censorship and the reinforcing of false beliefs. Using collaborative ethnography and theoretical insights from social studies of science and expertise, we offer a critical analysis of the process of building ML models for (mis)information classification - we identify a series of algorithmic contingencies--key moments during model development that could lead to different future outcomes, uncertainty and harmful effects as these tools are deployed by social media platforms. We conclude by offering a tentative path toward reflexive and responsible development of ML tools for moderating misinformation and other harmful content online.

  - title: Monitoring Model Deterioration with Explainable Uncertainty Estimation via Non-parametric Bootstrap
    url: https://doi.org/10.48550/arXiv.2201.11676
    authors:
      - Dan Saattrup Nielsen
      - Carlos Mougan
    venue: AAAI 2023
    abstract: Monitoring machine learning models once they are deployed is challenging. It is even more challenging to decide when to retrain models in real-case scenarios when labeled data is beyond reach, and monitoring performance metrics becomes unfeasible. In this work, we use non-parametric bootstrapped uncertainty estimates and SHAP values to provide explainable uncertainty estimation as a technique that aims to monitor the deterioration of machine learning models in deployment environments, as well as determine the source of model deterioration when target labels are not available. Classical methods are purely aimed at detecting distribution shift, which can lead to false positives in the sense that the model has not deteriorated despite a shift in the data distribution. To estimate model uncertainty we construct prediction intervals using a novel bootstrap method, which improves upon the work of Kumar & Srivastava (2012). We show that both our model deterioration detection system as well as our uncertainty estimation method achieve better performance than the current state-of-the-art. Finally, we use explainable AI techniques to gain an understanding of the drivers of model deterioration. We release an open source Python package, doubt, which implements our proposed methods, as well as the code used to reproduce our experiments.


2022:

  - title: MuMiN - A Large-Scale Multilingual Multimodal Fact-Checked Misinformation Social Network Dataset
    url: https://doi.org/10.48550/arXiv.2202.11684
    authors:
      - Dan Saattrup Nielsen
      - Ryan McConville
    venue: SIGIR 2022 and GLB 2022
    abstract: Misinformation is becoming increasingly prevalent on social media and in news articles. It has become so widespread that we require algorithmic assistance utilising machine learning to detect such content. Training these machine learning models require datasets of sufficient scale, diversity and quality. However, datasets in the field of automatic misinformation detection are predominantly monolingual, include a limited amount of modalities and are not of sufficient scale and quality. Addressing this, we develop a data collection and linking system (MuMiN-trawl), to build a public misinformation graph dataset (MuMiN), containing rich social media data (tweets, replies, users, images, articles, hashtags) spanning 21 million tweets belonging to 26 thousand Twitter threads, each of which have been semantically linked to 13 thousand fact-checked claims across dozens of topics, events and domains, in 41 different languages, spanning more than a decade. The dataset is made available as a heterogeneous graph via a Python package (mumin). We provide baseline results for two node classification tasks related to the veracity of a claim involving social media, and demonstrate that these are challenging tasks, with the highest macro-average F1-score being 62.55% and 61.45% for the two tasks, respectively. The MuMiN ecosystem is available at this https URL, including the data, documentation, tutorials and leaderboards.


2020:

  - title: Virtual Set Theory - Taking The Blue Pill (PhD thesis)
    url: https://github.com/saattrupdan/phd/blob/master/main.pdf
    authors:
      - Dan Saattrup Nielsen
    venue: University of Bristol
    abstract: The first part of this thesis is an analysis of the virtual large cardinals, being critical points of set-sized generic elementary embeddings where the target model is a subset of the ground model. We show that virtually measurables are equiconsistent with virtually strongs, and that virtually Woodins are virtually Vopenka. We separate most of these large cardinals, but show that such separations do not hold within core models. We define prestrong cardinals, being an equivalent characterisation of strongs, but which in a virtual setting are strictly weaker than virtually strongs. We show that the existence of this separation is equivalent to the existence of virtually rank-into-rank cardinals in the universe, and that virtually Berkeley cardinals can be characterised in the same fashion with On being virtually pre-Woodin but not virtually Woodin, answering a question by Gitman and Hamkins. Building on the work of Wilson, we show that the virtual version of the Weak Vopenka Principle is equivalent to a weakening of virtually pre-Woodins. We end the first part with several indestructibility results, including that a slight strengthening of the virtually supercompacts is always indestructible by <kappa-directed closed forcings. The second part is concerned with connections between the virtual large cardinals and other set-theoretic objects. We analyse cardinals arising from a certain filter game, for various lengths of the game. When the games are finite we show that this results in a characterisation of the completely ineffable cardinals, and at length omega we arrive at another characterisation of the virtually measurable cardinals. At length omega + 1 the cardinals become equiconsistent with a measurable cardinal, and at uncountable cofinalities the cardinals are downward absolute to K below 0-dagger. The results in this section answer most of the open questions raised in Holy and Schlicht (2018). We also introduce the notion of ideal-absolute properties of forcings, being properties such that generic elementary embeddings can be characterised by ideals in the ground model. We show that several properties are ideal-absolute, which includes an improvement of an unpublished theorem of Foreman. This also results in another characterisation of completely ineffables.


2019:

  - title: Games and Ramsey-like Cardinals
    url: https://doi.org/10.1017/jsl.2018.75
    authors:
      - Dan Saattrup Nielsen
      - Philip Welch
    venue: Journal of Symbolic Logic
    abstract: We generalise the alpha-Ramsey cardinals introduced in Holy and Schlicht (2018) for cardinals alpha to arbitrary ordinals alpha, and answer several questions posed in that paper. In particular, we show that alpha-Ramseys are downwards absolute to the core model K for all alpha of uncountable cofinality, that strategic omega-Ramsey cardinals are equiconsistent with remarkable cardinals and that strategic alpha-Ramsey cardinals are equiconsistent with measurable cardinals for all alpha > omega. We also show that the n-Ramseys satisfy indescribability properties and use them to provide a game-theoretic characterisation of completely ineffable cardinals, as well as establishing further connections between the alpha-Ramsey cardinals and the Ramsey-like cardinals introduced in Gitman (2011), Feng (1990), and Sharpe and Welch (2011).
