2025:
  - title: >
    MultiZebraLogic: A Multilingual Logical Reasoning Benchmark
    url: https://doi.org/10.48550/arXiv.2511.03553
    authors:
      - Sofie Helene Bruun
      - Dan Saattrup Smart
    venue: Under review
    abstract: >
      Measuring the full abilities of large language models (LLMs) requires benchmarks
      representing multiple tasks. We aim to create large, high-quality datasets for
      comparison of logical reasoning skills across several languages and of suitable
      difficulty for LLMs of various reasoning ability. We explore multiple ways of
      increasing difficulty. We generate zebra puzzles in multiple languages, themes,
      sizes and including 14 different clue types and 8 red herring types (uninformative
      clues). We find puzzle sizes 2x3 and 4x5 are sufficiently challenging for GPT-4o
      mini (a non-reasoning model) and o3-mini (a reasoning model), respectively.
      Including 5 red herrings decreases o3-mini puzzle-level accuracy on 4x5 puzzles by
      15.7%. Scores of o3-mini on 4x5 puzzles are not significantly affected by use of
      English vs. Danish or the common houses theme vs. the country-specific
      smoerrebroed theme. We find no correlation between difficulty and the selected
      clue types. Datasets of 128+1024 puzzles are published as MultiZebraLogic in each
      of nine Germanic languages for sizes 2x3 and 4x5. We publish code for puzzle
      generation, designed for adaptablity into more languages and themes.

  - title: >
      ValEU: A Survey-Driven Evaluation of LLM Cultural Value Alignment
    url: TBA
    authors:
      - Annika Simonsen
      - Maximilian Müller-Eberstein
      - Rob van der Goot
      - Hafsteinn Einarsson
      - Dan Saattrup Smart
    venue: Under review
    abstract: >
      We present ValEU, a framework for evaluating LLM alignment with European cultural
      values. Based on the 2017--2022 Integrated Values Surveys with responses from
      156,658 participants across 92 countries, we develop a data-driven, evolutionary
      question selection methodology for identifying values with high shared cultural
      importance for multi-national communities. Applied to delineating EU values, we
      identify 53 core value questions, for which our factor analysis reveals 15 primary
      value dimensions, including social liberalism, civic engagement, electoral
      integrity, and gender equality attitudes. Based on these questions, we develop a
      cultural alignment score using kernel density estimation fitted on
      demographics-weighted survey responses. Evaluating the EU alignment scores of 13
      LLMs, we find variation across model sizes, pre/post-training strategies, and
      question language, which are independent of general model capabilities. Going
      beyond standard multiple-choice prompt evaluation, we further test models' value
      choices in more realistic, situational scenarios. We find high sensitivity to
      situational context, where models with 96% alignment drop to 3-16%, especially
      for questions requiring embodiment, and ambiguous legality. Through our question
      selection and evaluation pipeline, we hope to highlight the current challenges,
      and promote a more holistic evaluation of LLMs' cultural alignment.

  - title: >
      MultiWikiQA: A Reading Comprehension Benchmark in 300+ Languages
    url: https://doi.org/10.48550/arXiv.2509.04111
    authors:
      - Dan Saattrup Smart
    venue: Under review
    abstract: >
      We introduce a new reading comprehension dataset, dubbed MultiWikiQA, which covers
      306 languages. The context data comes from Wikipedia articles, with questions
      generated by an LLM and the answers appearing verbatim in the Wikipedia articles.
      We conduct a crowdsourced human evaluation of the fluency of the generated
      questions across 30 of the languages, providing evidence that the questions are of
      good quality. We evaluate 6 different language models, both decoder and encoder
      models of varying sizes, showing that the benchmark is sufficiently difficult and
      that there is a large performance discrepancy amongst the languages. The dataset
      and survey evaluations are freely available.

  - title: >
      Encoder vs Decoder - Comparative Analysis of Encoder and Decoder Language Models
      on Multilingual NLU Tasks
    url: https://doi.org/10.48550/arXiv.2406.13469
    authors:
      - Dan Saattrup Smart
      - Kenneth Enevoldsen
      - Peter Schneider-Kamp
    venue: NoDaLiDa 2025
    abstract: >
      This paper explores the performance of encoder and decoder language models on
      multilingual Natural Language Understanding (NLU) tasks, with a broad focus on
      Germanic languages. Building upon the ScandEval benchmark, which initially was
      restricted to evaluating encoder models, we extend the evaluation framework to
      include decoder models. We introduce a method for evaluating decoder models on NLU
      tasks and apply it to the languages Danish, Swedish, Norwegian, Icelandic,
      Faroese, German, Dutch, and English. Through a series of experiments and analyses,
      we address key research questions regarding the comparative performance of encoder
      and decoder models, the impact of NLU task types, and the variation across
      language resources. Our findings reveal that decoder models can achieve
      significantly better NLU performance than encoder models, with nuances observed
      across different tasks and languages. Additionally, we investigate the correlation
      between decoders and task performance via a UMAP analysis, shedding light on the
      unique capabilities of decoder and encoder models. This study contributes to a
      deeper understanding of language model paradigms in NLU tasks and provides
      valuable insights for model selection and evaluation in multilingual settings.

  - title: FoQA - A Faroese Question-Answering Dataset
    url: https://doi.org/10.48550/arXiv.2502.07642
    authors:
      - Annika Simonsen
      - Dan Saattrup Smart
      - Hafsteinn Einarsson
    venue: NoDaLiDa 2025
    abstract: >
      We present FoQA, a Faroese extractive question-answering (QA) dataset with 2,000
      samples, created using a semi-automated approach combining Large Language Models
      (LLMs) and human validation. The dataset was generated from Faroese Wikipedia
      articles using GPT-4-turbo for initial QA generation, followed by question
      rephrasing to increase complexity and native speaker validation to ensure quality.
      We provide baseline performance metrics for FoQA across multiple models, including
      LLMs and BERT, demonstrating its effectiveness in evaluating Faroese QA
      performance. The dataset is released in three versions: a validated set of 2,000
      samples, a complete set of all 10,001 generated samples, and a set of 2,395
      rejected samples for error analysis.

  - title: >
      Hotter and Colder - A New Approach to Annotating Sentiment, Emotions, and Bias in
      Icelandic Blog Comments
    url: https://doi.org/10.48550/arXiv.2502.16987
    authors:
      - Steinunn Rut Friðriksdóttir
      - Dan Saattrup Smart
      - Hafsteinn Einarsson
    venue: NoDaLiDa 2025
    abstract: >
       This paper presents Hotter and Colder, a dataset designed to analyze various
       types of online behavior in Icelandic blog comments. Building on previous work,
       we used GPT-4o mini to annotate approximately 800,000 comments for 25 tasks,
       including sentiment analysis, emotion detection, hate speech, and group
       generalizations. Each comment was automatically labeled on a 5-point Likert
       scale. In a second annotation stage, comments with high or low probabilities of
       containing each examined behavior were subjected to manual revision. By
       leveraging crowdworkers to refine these automatically labeled comments, we ensure
       the quality and accuracy of our dataset resulting in 12,232 uniquely annotated
       comments and 19,301 annotations. Hotter and Colder provides an essential resource
       for advancing research in content moderation and automatically detectiong harmful
       online behaviors in Icelandic.

2024:
  - title: The Virtual Large Cardinal Hierarchy
    url: https://doi.org/10.48550/arXiv.2109.06079
    authors:
      - Stamatis Dimopoulos
      - Victoria Gitman
      - Dan Saattrup Smart
    venue: Fundamenta Mathematicae
    abstract: >
      We continue the study of the virtual large cardinal hierarchy by analysing virtual
      versions of superstrong, Woodin, and Berkeley cardinals. Gitman and Schindler
      showed that virtualizations of strong and supercompact cardinals yield the same
      large cardinal notion. We provide various equivalent characterizations of
      virtually Woodin cardinals, including showing that On is virtually Woodin if and
      only if for every class A, there is a proper class of virtually A-extendible
      cardinals. We introduce the virtual Vopenka principle for finite languages and
      show that it is not equivalent to the virtual Vopenka principle (although the two
      principles are equiconsistent), but is equivalent to the assertion that On is
      virtually pre-Woodin, a weakening of virtually Woodin, which is equivalent to
      having for every class A, a weakly virtually A-extendible cardinal. We show that
      if there are no virtually Berkeley cardinals, then On is virtually Woodin if and
      only if On is virtually pre-Woodin (if and only if the virtual Vopenka principle
      for finite languages holds). In particular, if the virtual Vopenka principle holds
      and On is not Mahlo, then On is not virtually Woodin, and hence there is a
      virtually Berkeley cardinal.

2023:
  - title: Danish Foundation Models
    url: https://doi.org/10.48550/arXiv.2311.07264
    authors:
      - Kenneth Enevoldsen
      - Lasse Hansen
      - Dan Saattrup Smart
      - Rasmus A. F. Egebæk
      - Søren V. Holm
      - Martin C. Smart
      - Martin Bernstorff
      - Rasmus Larsen
      - Peter B. Jørgensen
      - Malte Højmark-Bertelsen
      - Peter B. Vahlstrup
      - Per Møldrup-Dalum
      - Kristoffer Nielbo
    venue: ArXiv preprint
    abstract: >
      Large language models, sometimes referred to as foundation models, have
      transformed multiple fields of research. However, smaller languages risk falling
      behind due to high training costs and small incentives for large companies to
      train these models. To combat this, the Danish Foundation Models project seeks to
      provide and maintain open, well-documented, and high-quality foundation models for
      the Danish language. This is achieved through broad cooperation with public and
      private institutions, to ensure high data quality and applicability of the trained
      models. We present the motivation of the project, the current status, and future
      perspectives.

  - title: Model Agnostic Explainable Selective Regression via Uncertainty Estimation
    url: https://doi.org/10.48550/arXiv.2311.09145
    authors:
      - Andrea Pugnana
      - Carlos Mougan
      - Dan Saattrup Smart
    venue: ArXiv preprint
    abstract: >
      With the wide adoption of machine learning techniques, requirements have evolved
      beyond sheer high performance, often requiring models to be trustworthy. A common
      approach to increase the trustworthiness of such systems is to allow them to
      refrain from predicting. Such a framework is known as selective prediction. While
      selective prediction for classification tasks has been widely analyzed, the
      problem of selective regression is understudied. This paper presents a novel
      approach to selective regression that utilizes model-agnostic non-parametric
      uncertainty estimation. Our proposed framework showcases superior performance
      compared to state-of-the-art selective regressors, as demonstrated through
      comprehensive benchmarking on 69 datasets. Finally, we use explainable AI
      techniques to gain an understanding of the drivers behind selective regression. We
      implement our selective regression method in the open-source Python package doubt
      and release the code used to reproduce our experiments.

  - title: ScandEval - A Benchmark for Scandinavian Natural Language Processing
    url: https://doi.org/10.48550/arXiv.2304.00906
    authors:
      - Dan Saattrup Smart
    venue: NoDaLiDa 2023
    abstract: >
      This paper introduces a Scandinavian benchmarking platform, ScandEval, which can
      benchmark any pretrained model on four different tasks in the Scandinavian
      languages. The datasets used in two of the tasks, linguistic acceptability and
      question answering, are new. We develop and release a Python package and
      command-line interface, scandeval, which can benchmark any model that has been
      uploaded to the Hugging Face Hub, with reproducible results. Using this package,
      we benchmark more than 80 Scandinavian or multilingual models and present the
      results of these in an interactive online leaderboard, as well as provide an
      analysis of the results. The analysis shows that there is substantial
      cross-lingual transfer among the the Mainland Scandinavian languages (Danish,
      Swedish and Norwegian), with limited cross-lingual transfer between the group of
      Mainland Scandinavian languages and the group of Insular Scandinavian languages
      (Icelandic and Faroese). The benchmarking results also show that the investment in
      language technology in Norway and Sweden has led to language models that
      outperform massively multilingual models such as XLM-RoBERTa and mDeBERTaV3. We
      release the source code for both the package.

  - title: >
      Addressing contingency in algorithmic (mis)information classification - Toward a
      responsible machine learning agenda
    url: https://doi.org/10.48550/arXiv.2210.09014
    authors:
      - Andrés Domínguez Hernández
      - Richard Owen
      - Dan Saattrup Smart
      - Ryan McConville
    venue: FAccT 2023 and Journal of Responsible Innovation
    abstract: >
      Machine learning (ML) enabled classification models are becoming increasingly
      popular for tackling the sheer volume and speed of online misinformation and other
      content that could be identified as harmful. In building these models, data
      scientists need to take a stance on the legitimacy, authoritativeness and
      objectivity of the sources of ``truth" used for model training and testing. This
      has political, ethical and epistemic implications which are rarely addressed in
      technical papers. Despite (and due to) their reported high accuracy and
      performance, ML-driven moderation systems have the potential to shape online
      public debate and create downstream negative impacts such as undue censorship and
      the reinforcing of false beliefs. Using collaborative ethnography and theoretical
      insights from social studies of science and expertise, we offer a critical
      analysis of the process of building ML models for (mis)information classification
      - we identify a series of algorithmic contingencies--key moments during model
      development that could lead to different future outcomes, uncertainty and harmful
      effects as these tools are deployed by social media platforms. We conclude by
      offering a tentative path toward reflexive and responsible development of ML tools
      for moderating misinformation and other harmful content online.

  - title: >
      Monitoring Model Deterioration with Explainable Uncertainty Estimation via
      Non-parametric Bootstrap
    url: https://doi.org/10.48550/arXiv.2201.11676
    authors:
      - Dan Saattrup Smart
      - Carlos Mougan
    venue: AAAI 2023
    abstract: >
      Monitoring machine learning models once they are deployed is challenging. It is
      even more challenging to decide when to retrain models in real-case scenarios when
      labeled data is beyond reach, and monitoring performance metrics becomes
      unfeasible. In this work, we use non-parametric bootstrapped uncertainty estimates
      and SHAP values to provide explainable uncertainty estimation as a technique that
      aims to monitor the deterioration of machine learning models in deployment
      environments, as well as determine the source of model deterioration when target
      labels are not available. Classical methods are purely aimed at detecting
      distribution shift, which can lead to false positives in the sense that the model
      has not deteriorated despite a shift in the data distribution. To estimate model
      uncertainty we construct prediction intervals using a novel bootstrap method,
      which improves upon the work of Kumar & Srivastava (2012). We show that both our
      model deterioration detection system as well as our uncertainty estimation method
      achieve better performance than the current state-of-the-art. Finally, we use
      explainable AI techniques to gain an understanding of the drivers of model
      deterioration. We release an open source Python package, doubt, which implements
      our proposed methods, as well as the code used to reproduce our experiments.

2022:
  - title: >
      MuMiN - A Large-Scale Multilingual Multimodal Fact-Checked Misinformation Social
      Network Dataset
    url: https://doi.org/10.48550/arXiv.2202.11684
    authors:
      - Dan Saattrup Smart
      - Ryan McConville
    venue: SIGIR 2022 and GLB 2022
    abstract: >
      Misinformation is becoming increasingly prevalent on social media and in news
      articles. It has become so widespread that we require algorithmic assistance
      utilising machine learning to detect such content. Training these machine learning
      models require datasets of sufficient scale, diversity and quality. However,
      datasets in the field of automatic misinformation detection are predominantly
      monolingual, include a limited amount of modalities and are not of sufficient
      scale and quality. Addressing this, we develop a data collection and linking
      system (MuMiN-trawl), to build a public misinformation graph dataset (MuMiN),
      containing rich social media data (tweets, replies, users, images, articles,
      hashtags) spanning 21 million tweets belonging to 26 thousand Twitter threads,
      each of which have been semantically linked to 13 thousand fact-checked claims
      across dozens of topics, events and domains, in 41 different languages, spanning
      more than a decade. The dataset is made available as a heterogeneous graph via a
      Python package (mumin). We provide baseline results for two node classification
      tasks related to the veracity of a claim involving social media, and demonstrate
      that these are challenging tasks, with the highest macro-average F1-score being
      62.55% and 61.45% for the two tasks, respectively. The MuMiN ecosystem is
      available at this https URL, including the data, documentation, tutorials and
      leaderboards.

2020:
  - title: Virtual Set Theory - Taking The Blue Pill (PhD thesis)
    url: https://github.com/saattrupdan/phd/blob/master/main.pdf
    authors:
      - Dan Saattrup Smart
    venue: University of Bristol
    abstract: >
      The first part of this thesis is an analysis of the virtual large cardinals, being
      critical points of set-sized generic elementary embeddings where the target model
      is a subset of the ground model. We show that virtually measurables are
      equiconsistent with virtually strongs, and that virtually Woodins are virtually
      Vopenka. We separate most of these large cardinals, but show that such separations
      do not hold within core models. We define prestrong cardinals, being an equivalent
      characterisation of strongs, but which in a virtual setting are strictly weaker
      than virtually strongs. We show that the existence of this separation is
      equivalent to the existence of virtually rank-into-rank cardinals in the universe,
      and that virtually Berkeley cardinals can be characterised in the same fashion
      with On being virtually pre-Woodin but not virtually Woodin, answering a question
      by Gitman and Hamkins. Building on the work of Wilson, we show that the virtual
      version of the Weak Vopenka Principle is equivalent to a weakening of virtually
      pre-Woodins. We end the first part with several indestructibility results,
      including that a slight strengthening of the virtually supercompacts is always
      indestructible by <kappa-directed closed forcings. The second part is concerned
      with connections between the virtual large cardinals and other set-theoretic
      objects. We analyse cardinals arising from a certain filter game, for various
      lengths of the game. When the games are finite we show that this results in a
      characterisation of the completely ineffable cardinals, and at length omega we
      arrive at another characterisation of the virtually measurable cardinals. At
      length omega + 1 the cardinals become equiconsistent with a measurable cardinal,
      and at uncountable cofinalities the cardinals are downward absolute to K below
      0-dagger. The results in this section answer most of the open questions raised in
      Holy and Schlicht (2018). We also introduce the notion of ideal-absolute
      properties of forcings, being properties such that generic elementary embeddings
      can be characterised by ideals in the ground model. We show that several
      properties are ideal-absolute, which includes an improvement of an unpublished
      theorem of Foreman. This also results in another characterisation of completely
      ineffables.

2019:
  - title: Games and Ramsey-like Cardinals
    url: https://doi.org/10.1017/jsl.2018.75
    authors:
      - Dan Saattrup Smart
      - Philip Welch
    venue: Journal of Symbolic Logic
    abstract: >
      We generalise the alpha-Ramsey cardinals introduced in Holy and Schlicht (2018)
      for cardinals alpha to arbitrary ordinals alpha, and answer several questions
      posed in that paper. In particular, we show that alpha-Ramseys are downwards
      absolute to the core model K for all alpha of uncountable cofinality, that
      strategic omega-Ramsey cardinals are equiconsistent with remarkable cardinals and
      that strategic alpha-Ramsey cardinals are equiconsistent with measurable cardinals
      for all alpha > omega. We also show that the n-Ramseys satisfy indescribability
      properties and use them to provide a game-theoretic characterisation of completely
      ineffable cardinals, as well as establishing further connections between the
      alpha-Ramsey cardinals and the Ramsey-like cardinals introduced in Gitman (2011),
      Feng (1990), and Sharpe and Welch (2011).
